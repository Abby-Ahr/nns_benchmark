SRS - Fast Approximate Nearest Neighbor Search in High Dimensional Euclidean Space With a Tiny Index
====================================================================================================

Please refer to our (GitHub reposit)[https://github.com/DBWangGroupUNSW/SRS] for more details.

Features
--------

* **Guaranteed Success Probability**

  Theoretically, SRS guarantees to return a _c_-approximate nearest neighbor to
  the query with a user specified probability even in the worst case. For
  example, many heuristic methods will not return a near neighbor on some hard
  datasets (e.g., those generated by `gen_hard_data`).

  There are several other unique theoretical properties of the SRS algorithm.
  The top-_k_ version of SRS guarantees to return _c_-_k_-approximate nearest
  neighbors with constant probability (while previous methods have no guarantee
  for _k_ > 1), and the `SRS-1` algorithm guarantees to return *nearest
  neighbor* (i.e., _c_ = 1) to the query with any user specified success
  probability.
  
* **Small Index Size**

  The index size of SRS is substantially smaller than the size of original data.
  For example, the index size for a 12GB data set (8 million 384-dimension
  points) is only 337MB. This means that the SRS index usually can be
  accommodated _entirely_ in the main memory.

  As a side note, our index and query processing algorithm is independent of the
  dimensionality of the dataset, i.e., it works for arbitrarily high dimensions. 
  
* **Rich Functionality**

  The users can easily achieve a space-time balance by tuning parameters even
  after the index has been built. All four variants of the query processing
  algorithm in the paper are supported.




How it works
----------------

In a nutshell, SRS reduces the problem of "approximate NN search in high
dimensional space" to a "exact T-NN search in a low dimensional space". 

In the indexing phase, SRS projects data points from the original
high-dimensional space into an appropriately chosen *m*-dimensional space via
2-stable random projections, and then uses a cover-tree to index these projected
points.

The key observation is that the inter-point distance in the projected space
(called _Projected Distance_) over that in the original high-dimensional space
follows a scaled chi-squared distribution, which has a sharp concentration bound.
Therefore, given any threshold on the projected distance, and for any point _o_,
we can compute exactly the probability that _o_'s projected distance is within the
threshold.

In the querying phase, SRS performs an incrementally _k_-NN search on the
projected space, until when it has found a satisfactory point (i.e.,
early-termination condition), or it has examined _t * n_ points (i.e.,
normal-termination condition).

Before start
------------

* The users need to have Boost C++ library installed (http://www.boost.org/).
  The Boost library is used to calculate the quantile of chi-squared
  distribution.
* Currently the program has only been tested on Linux.
* There are four key parameters to the SRS algorithms:
  * _n_: number of data points. 
  * _c_: approximation ratio. 
  * _m_: number of 2-stable random projections to be used in the index. 
  * _prob\_thres_: the probability that the algorithm returns a _c_-approximate NN. 
  Typically, _n_ is fixed, and one can fine tune the other three parameters to
  achieve different space/time/quality tradoffs. Fixing any of the two
  parameters will place a constraint on the third parameter.
* In addition to these input parameters, the program also generate an internal
  parameter _t_: the fraction of data points to be examined before the search
  terminates in the normal condition. 

How to use SRS
--------------

1. Compile the program (SRS/src)

  ```
  % make all
  ```

2. Build Index (SRS/script)

  ```
  % build.sh

  ```
3. Conduct search (SRS/script)

  ```
  % search.sh
  ```


Data Format
-----------

1. Data file should contain _n_ lines, where _n_ is the cardinality of the
   dataset. The file should be formatted as:

  ```
  e_1_1 e_1_2 ... e_1_d
  ...
  e_n_1 e_n_2 ... e_n_d
  ```
  
  where `e_i_j`s are integers, and are separated by whitespace.

2. Query file should contain _N+1_ lines, where _N_ is the number of queries in the
   query workload. The file should be formatted as:
  
  ```
  N d
  ID_1 e_1_1 e_1_2 ... e_1_d
  ...
  ID_N e_N_1 e_N_2 ... e_N_d
  ```
  where _d_ is the dimensionality, `e_i_j` is an integer, and separated by whitespace.

 ```

